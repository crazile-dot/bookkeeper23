<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="it"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>SingleDirectoryDbLedgerStorage.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">Tests</a> &gt; <a href="../index.html" class="el_bundle">bookkeeper-server</a> &gt; <a href="index.source.html" class="el_package">org.apache.bookkeeper.bookie.storage.ldb</a> &gt; <span class="el_source">SingleDirectoryDbLedgerStorage.java</span></div><h1>SingleDirectoryDbLedgerStorage.java</h1><pre class="source lang-java linenums">/**
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 *
 */
package org.apache.bookkeeper.bookie.storage.ldb;

import static com.google.common.base.Preconditions.checkArgument;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.collect.Lists;
import com.google.protobuf.ByteString;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.ByteBufAllocator;
import io.netty.buffer.Unpooled;
import io.netty.util.concurrent.DefaultThreadFactory;

import java.io.File;
import java.io.IOException;
import java.util.Collections;
import java.util.List;
import java.util.PrimitiveIterator.OfLong;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.ReentrantLock;
import java.util.concurrent.locks.StampedLock;

import org.apache.bookkeeper.bookie.Bookie;
import org.apache.bookkeeper.bookie.Bookie.NoEntryException;
import org.apache.bookkeeper.bookie.BookieException;
import org.apache.bookkeeper.bookie.BookieException.OperationRejectedException;
import org.apache.bookkeeper.bookie.CheckpointSource;
import org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint;
import org.apache.bookkeeper.bookie.Checkpointer;
import org.apache.bookkeeper.bookie.CompactableLedgerStorage;
import org.apache.bookkeeper.bookie.EntryLocation;
import org.apache.bookkeeper.bookie.EntryLogger;
import org.apache.bookkeeper.bookie.GarbageCollectionStatus;
import org.apache.bookkeeper.bookie.GarbageCollectorThread;
import org.apache.bookkeeper.bookie.LastAddConfirmedUpdateNotification;
import org.apache.bookkeeper.bookie.LedgerCache;
import org.apache.bookkeeper.bookie.LedgerDirsManager;
import org.apache.bookkeeper.bookie.LedgerDirsManager.LedgerDirsListener;
import org.apache.bookkeeper.bookie.LedgerEntryPage;
import org.apache.bookkeeper.bookie.StateManager;
//import org.apache.bookkeeper.bookie.storage.ldb.DbLedgerStorageDataFormats.LedgerData;
import org.apache.bookkeeper.bookie.storage.ldb.KeyValueStorage.Batch;
import org.apache.bookkeeper.common.util.Watcher;
import org.apache.bookkeeper.conf.ServerConfiguration;
import org.apache.bookkeeper.meta.LedgerManager;
import org.apache.bookkeeper.proto.BookieProtocol;
import org.apache.bookkeeper.stats.OpStatsLogger;
import org.apache.bookkeeper.stats.StatsLogger;
import org.apache.bookkeeper.util.MathUtils;
import org.apache.bookkeeper.util.collections.ConcurrentLongHashMap;
import org.apache.commons.lang.mutable.MutableLong;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Single directory implementation of LedgerStorage that uses RocksDB to keep the indexes for entries stored in
 * EntryLogs.
 *
 * &lt;p&gt;This is meant only to be used from {@link DbLedgerStorage}.
 */
public class SingleDirectoryDbLedgerStorage implements CompactableLedgerStorage {
    private final EntryLogger entryLogger;

    private final LedgerMetadataIndex ledgerIndex;
    private final EntryLocationIndex entryLocationIndex;

    private final ConcurrentLongHashMap&lt;TransientLedgerInfo&gt; transientLedgerInfoCache;

    private final GarbageCollectorThread gcThread;

    // Write cache where all new entries are inserted into
    protected volatile WriteCache writeCache;

    // Write cache that is used to swap with writeCache during flushes
    protected volatile WriteCache writeCacheBeingFlushed;

    // Cache where we insert entries for speculative reading
    private final ReadCache readCache;

<span class="nc" id="L105">    private final StampedLock writeCacheRotationLock = new StampedLock();</span>

<span class="nc" id="L107">    protected final ReentrantLock flushMutex = new ReentrantLock();</span>

<span class="nc" id="L109">    protected final AtomicBoolean hasFlushBeenTriggered = new AtomicBoolean(false);</span>
<span class="nc" id="L110">    private final AtomicBoolean isFlushOngoing = new AtomicBoolean(false);</span>

<span class="nc" id="L112">    private final ExecutorService executor = Executors.newSingleThreadExecutor(new DefaultThreadFactory(&quot;db-storage&quot;));</span>

    // Executor used to for db index cleanup
<span class="nc" id="L115">    private final ScheduledExecutorService cleanupExecutor = Executors</span>
<span class="nc" id="L116">            .newSingleThreadScheduledExecutor(new DefaultThreadFactory(&quot;db-storage-cleanup&quot;));</span>

<span class="nc" id="L118">    private final CopyOnWriteArrayList&lt;LedgerDeletionListener&gt; ledgerDeletionListeners = Lists</span>
<span class="nc" id="L119">            .newCopyOnWriteArrayList();</span>

    private final CheckpointSource checkpointSource;
<span class="nc" id="L122">    private Checkpoint lastCheckpoint = Checkpoint.MIN;</span>

    private final long writeCacheMaxSize;
    private final long readCacheMaxSize;
    private final int readAheadCacheBatchSize;

    private final long maxThrottleTimeNanos;

    private final DbLedgerStorageStats dbLedgerStorageStats;

    static final String READ_AHEAD_CACHE_BATCH_SIZE = &quot;dbStorage_readAheadCacheBatchSize&quot;;
    private static final int DEFAULT_READ_AHEAD_CACHE_BATCH_SIZE = 100;

<span class="nc" id="L135">    private static final long DEFAULT_MAX_THROTTLE_TIME_MILLIS = TimeUnit.SECONDS.toMillis(10);</span>

    private final long maxReadAheadBytesSize;

    public SingleDirectoryDbLedgerStorage(ServerConfiguration conf, LedgerManager ledgerManager,
            LedgerDirsManager ledgerDirsManager, LedgerDirsManager indexDirsManager, StateManager stateManager,
            CheckpointSource checkpointSource, Checkpointer checkpointer, StatsLogger statsLogger,
            ByteBufAllocator allocator, ScheduledExecutorService gcExecutor, long writeCacheSize, long readCacheSize)
<span class="nc" id="L143">            throws IOException {</span>

<span class="nc bnc" id="L145" title="All 2 branches missed.">        checkArgument(ledgerDirsManager.getAllLedgerDirs().size() == 1,</span>
                &quot;Db implementation only allows for one storage dir&quot;);

<span class="nc" id="L148">        String baseDir = ledgerDirsManager.getAllLedgerDirs().get(0).toString();</span>
<span class="nc" id="L149">        log.info(&quot;Creating single directory db ledger storage on {}&quot;, baseDir);</span>

<span class="nc" id="L151">        this.writeCacheMaxSize = writeCacheSize;</span>
<span class="nc" id="L152">        this.writeCache = new WriteCache(allocator, writeCacheMaxSize / 2);</span>
<span class="nc" id="L153">        this.writeCacheBeingFlushed = new WriteCache(allocator, writeCacheMaxSize / 2);</span>

<span class="nc" id="L155">        this.checkpointSource = checkpointSource;</span>

<span class="nc" id="L157">        readCacheMaxSize = readCacheSize;</span>
<span class="nc" id="L158">        readAheadCacheBatchSize = conf.getInt(READ_AHEAD_CACHE_BATCH_SIZE, DEFAULT_READ_AHEAD_CACHE_BATCH_SIZE);</span>

        // Do not attempt to perform read-ahead more than half the total size of the cache
<span class="nc" id="L161">        maxReadAheadBytesSize = readCacheMaxSize / 2;</span>

<span class="nc" id="L163">        long maxThrottleTimeMillis = conf.getLong(DbLedgerStorage.MAX_THROTTLE_TIME_MILLIS,</span>
                DEFAULT_MAX_THROTTLE_TIME_MILLIS);
<span class="nc" id="L165">        maxThrottleTimeNanos = TimeUnit.MILLISECONDS.toNanos(maxThrottleTimeMillis);</span>

<span class="nc" id="L167">        readCache = new ReadCache(allocator, readCacheMaxSize);</span>

<span class="nc" id="L169">        ledgerIndex = new LedgerMetadataIndex(conf, KeyValueStorageRocksDB.factory, baseDir, statsLogger);</span>
<span class="nc" id="L170">        entryLocationIndex = new EntryLocationIndex(conf, KeyValueStorageRocksDB.factory, baseDir, statsLogger);</span>

<span class="nc" id="L172">        transientLedgerInfoCache = new ConcurrentLongHashMap&lt;&gt;(16 * 1024,</span>
<span class="nc" id="L173">                Runtime.getRuntime().availableProcessors() * 2);</span>
<span class="nc" id="L174">        cleanupExecutor.scheduleAtFixedRate(this::cleanupStaleTransientLedgerInfo,</span>
                TransientLedgerInfo.LEDGER_INFO_CACHING_TIME_MINUTES,
                TransientLedgerInfo.LEDGER_INFO_CACHING_TIME_MINUTES, TimeUnit.MINUTES);

<span class="nc" id="L178">        entryLogger = new EntryLogger(conf, ledgerDirsManager, null, statsLogger, allocator);</span>
<span class="nc" id="L179">        gcThread = new GarbageCollectorThread(conf, ledgerManager, this, statsLogger);</span>

<span class="nc" id="L181">        dbLedgerStorageStats = new DbLedgerStorageStats(</span>
            statsLogger,
<span class="nc" id="L183">            () -&gt; writeCache.size() + writeCacheBeingFlushed.size(),</span>
<span class="nc" id="L184">            () -&gt; writeCache.count() + writeCacheBeingFlushed.count(),</span>
<span class="nc" id="L185">            () -&gt; readCache.size(),</span>
<span class="nc" id="L186">            () -&gt; readCache.count()</span>
        );
<span class="nc" id="L188">        ledgerDirsManager.addLedgerDirsListener(getLedgerDirsListener());</span>
<span class="nc" id="L189">    }</span>

    @Override
    public void initialize(ServerConfiguration conf, LedgerManager ledgerManager, LedgerDirsManager ledgerDirsManager,
            LedgerDirsManager indexDirsManager, StateManager stateManager, CheckpointSource checkpointSource,
            Checkpointer checkpointer, StatsLogger statsLogger,
            ByteBufAllocator allocator) throws IOException {
        /// Initialized in constructor
<span class="nc" id="L197">    }</span>

    /**
     * Evict all the ledger info object that were not used recently.
     */
    private void cleanupStaleTransientLedgerInfo() {
<span class="nc" id="L203">        transientLedgerInfoCache.removeIf((ledgerId, ledgerInfo) -&gt; {</span>
<span class="nc" id="L204">            boolean isStale = ledgerInfo.isStale();</span>
<span class="nc bnc" id="L205" title="All 2 branches missed.">            if (isStale) {</span>
<span class="nc" id="L206">                ledgerInfo.close();</span>
            }

<span class="nc" id="L209">            return isStale;</span>
        });
<span class="nc" id="L211">    }</span>

    @Override
    public void start() {
<span class="nc" id="L215">        gcThread.start();</span>
<span class="nc" id="L216">    }</span>

    @Override
    public void forceGC() {
<span class="nc" id="L220">        gcThread.enableForceGC();</span>
<span class="nc" id="L221">    }</span>

    @Override
    public boolean isInForceGC() {
<span class="nc" id="L225">        return gcThread.isInForceGC();</span>
    }

    @Override
    public void shutdown() throws InterruptedException {
        try {
<span class="nc" id="L231">            flush();</span>

<span class="nc" id="L233">            gcThread.shutdown();</span>
<span class="nc" id="L234">            entryLogger.shutdown();</span>

<span class="nc" id="L236">            cleanupExecutor.shutdown();</span>
<span class="nc" id="L237">            cleanupExecutor.awaitTermination(1, TimeUnit.SECONDS);</span>

<span class="nc" id="L239">            ledgerIndex.close();</span>
<span class="nc" id="L240">            entryLocationIndex.close();</span>

<span class="nc" id="L242">            writeCache.close();</span>
<span class="nc" id="L243">            writeCacheBeingFlushed.close();</span>
<span class="nc" id="L244">            readCache.close();</span>
<span class="nc" id="L245">            executor.shutdown();</span>

<span class="nc" id="L247">        } catch (IOException e) {</span>
<span class="nc" id="L248">            log.error(&quot;Error closing db storage&quot;, e);</span>
<span class="nc" id="L249">        }</span>
<span class="nc" id="L250">    }</span>

    @Override
    public boolean ledgerExists(long ledgerId) throws IOException {
        try {
            //LedgerData ledgerData = ledgerIndex.get(ledgerId);
            /*if (log.isDebugEnabled()) {
                log.debug(&quot;Ledger exists. ledger: {} : {}&quot;, ledgerId, ledgerData.getExists());
            }
            return ledgerData.getExists();*/
        } catch (Exception nle) {
            // ledger does not exist
            return false;
        }
<span class="nc" id="L264">        return true;</span>
    }

    @Override
    public boolean isFenced(long ledgerId) throws IOException {
<span class="nc bnc" id="L269" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L270">            log.debug(&quot;isFenced. ledger: {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L272">        return true;</span>
    }

    @Override
    public boolean setFenced(long ledgerId) throws IOException {
<span class="nc bnc" id="L277" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L278">            log.debug(&quot;Set fenced. ledger: {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L280">        boolean changed = ledgerIndex.setFenced(ledgerId);</span>
<span class="nc bnc" id="L281" title="All 2 branches missed.">        if (changed) {</span>
            // notify all the watchers if a ledger is fenced
<span class="nc" id="L283">            TransientLedgerInfo ledgerInfo = transientLedgerInfoCache.get(ledgerId);</span>
<span class="nc bnc" id="L284" title="All 2 branches missed.">            if (null != ledgerInfo) {</span>
<span class="nc" id="L285">                ledgerInfo.notifyWatchers(Long.MAX_VALUE);</span>
            }
        }
<span class="nc" id="L288">        return changed;</span>
    }

    @Override
    public void setMasterKey(long ledgerId, byte[] masterKey) throws IOException {
<span class="nc bnc" id="L293" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L294">            log.debug(&quot;Set master key. ledger: {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L296">        ledgerIndex.setMasterKey(ledgerId, masterKey);</span>
<span class="nc" id="L297">    }</span>

    @Override
    public byte[] readMasterKey(long ledgerId) throws IOException, BookieException {
<span class="nc bnc" id="L301" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L302">            log.debug(&quot;Read master key. ledger: {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L304">        return null;</span>
    }

    @Override
    public long addEntry(ByteBuf entry) throws IOException, BookieException {
<span class="nc" id="L309">        long startTime = MathUtils.nowInNano();</span>

<span class="nc" id="L311">        long ledgerId = entry.getLong(entry.readerIndex());</span>
<span class="nc" id="L312">        long entryId = entry.getLong(entry.readerIndex() + 8);</span>
<span class="nc" id="L313">        long lac = entry.getLong(entry.readerIndex() + 16);</span>

<span class="nc bnc" id="L315" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L316">            log.debug(&quot;Add entry. {}@{}, lac = {}&quot;, ledgerId, entryId, lac);</span>
        }

        // First we try to do an optimistic locking to get access to the current write cache.
        // This is based on the fact that the write cache is only being rotated (swapped) every 1 minute. During the
        // rest of the time, we can have multiple thread using the optimistic lock here without interfering.
<span class="nc" id="L322">        long stamp = writeCacheRotationLock.tryOptimisticRead();</span>
<span class="nc" id="L323">        boolean inserted = false;</span>

<span class="nc" id="L325">        inserted = writeCache.put(ledgerId, entryId, entry);</span>
<span class="nc bnc" id="L326" title="All 2 branches missed.">        if (!writeCacheRotationLock.validate(stamp)) {</span>
            // The write cache was rotated while we were inserting. We need to acquire the proper read lock and repeat
            // the operation because we might have inserted in a write cache that was already being flushed and cleared,
            // without being sure about this last entry being flushed or not.
<span class="nc" id="L330">            stamp = writeCacheRotationLock.readLock();</span>
            try {
<span class="nc" id="L332">                inserted = writeCache.put(ledgerId, entryId, entry);</span>
            } finally {
<span class="nc" id="L334">                writeCacheRotationLock.unlockRead(stamp);</span>
            }
        }

<span class="nc bnc" id="L338" title="All 2 branches missed.">        if (!inserted) {</span>
<span class="nc" id="L339">            triggerFlushAndAddEntry(ledgerId, entryId, entry);</span>
        }

        // after successfully insert the entry, update LAC and notify the watchers
<span class="nc" id="L343">        updateCachedLacIfNeeded(ledgerId, lac);</span>

<span class="nc" id="L345">        recordSuccessfulEvent(dbLedgerStorageStats.getAddEntryStats(), startTime);</span>
<span class="nc" id="L346">        return entryId;</span>
    }

    private void triggerFlushAndAddEntry(long ledgerId, long entryId, ByteBuf entry)
            throws IOException, BookieException {
<span class="nc" id="L351">        dbLedgerStorageStats.getThrottledWriteRequests().inc();</span>
<span class="nc" id="L352">        long absoluteTimeoutNanos = System.nanoTime() + maxThrottleTimeNanos;</span>

<span class="nc bnc" id="L354" title="All 2 branches missed.">        while (System.nanoTime() &lt; absoluteTimeoutNanos) {</span>
            // Write cache is full, we need to trigger a flush so that it gets rotated
            // If the flush has already been triggered or flush has already switched the
            // cache, we don't need to trigger another flush
<span class="nc bnc" id="L358" title="All 4 branches missed.">            if (!isFlushOngoing.get() &amp;&amp; hasFlushBeenTriggered.compareAndSet(false, true)) {</span>
                // Trigger an early flush in background
<span class="nc" id="L360">                log.info(&quot;Write cache is full, triggering flush&quot;);</span>
<span class="nc" id="L361">                executor.execute(() -&gt; {</span>
                        try {
<span class="nc" id="L363">                            flush();</span>
<span class="nc" id="L364">                        } catch (IOException e) {</span>
<span class="nc" id="L365">                            log.error(&quot;Error during flush&quot;, e);</span>
<span class="nc" id="L366">                        }</span>
<span class="nc" id="L367">                    });</span>
            }

<span class="nc" id="L370">            long stamp = writeCacheRotationLock.readLock();</span>
            try {
<span class="nc bnc" id="L372" title="All 2 branches missed.">                if (writeCache.put(ledgerId, entryId, entry)) {</span>
                    // We succeeded in putting the entry in write cache in the
<span class="nc" id="L374">                    return;</span>
                }
            } finally {
<span class="nc" id="L377">                writeCacheRotationLock.unlockRead(stamp);</span>
            }

            // Wait some time and try again
            try {
<span class="nc" id="L382">                Thread.sleep(1);</span>
<span class="nc" id="L383">            } catch (InterruptedException e) {</span>
<span class="nc" id="L384">                Thread.currentThread().interrupt();</span>
<span class="nc" id="L385">                throw new IOException(&quot;Interrupted when adding entry &quot; + ledgerId + &quot;@&quot; + entryId);</span>
<span class="nc" id="L386">            }</span>
<span class="nc" id="L387">        }</span>

        // Timeout expired and we weren't able to insert in write cache
<span class="nc" id="L390">        dbLedgerStorageStats.getRejectedWriteRequests().inc();</span>
<span class="nc" id="L391">        throw new OperationRejectedException();</span>
    }

    @Override
    public ByteBuf getEntry(long ledgerId, long entryId) throws IOException {
<span class="nc" id="L396">        long startTime = MathUtils.nowInNano();</span>
<span class="nc bnc" id="L397" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L398">            log.debug(&quot;Get Entry: {}@{}&quot;, ledgerId, entryId);</span>
        }

<span class="nc bnc" id="L401" title="All 2 branches missed.">        if (entryId == BookieProtocol.LAST_ADD_CONFIRMED) {</span>
<span class="nc" id="L402">            return getLastEntry(ledgerId);</span>
        }

        // We need to try to read from both write caches, since recent entries could be found in either of the two. The
        // write caches are already thread safe on their own, here we just need to make sure we get references to both
        // of them. Using an optimistic lock since the read lock is always free, unless we're swapping the caches.
<span class="nc" id="L408">        long stamp = writeCacheRotationLock.tryOptimisticRead();</span>
<span class="nc" id="L409">        WriteCache localWriteCache = writeCache;</span>
<span class="nc" id="L410">        WriteCache localWriteCacheBeingFlushed = writeCacheBeingFlushed;</span>
<span class="nc bnc" id="L411" title="All 2 branches missed.">        if (!writeCacheRotationLock.validate(stamp)) {</span>
            // Fallback to regular read lock approach
<span class="nc" id="L413">            stamp = writeCacheRotationLock.readLock();</span>
            try {
<span class="nc" id="L415">                localWriteCache = writeCache;</span>
<span class="nc" id="L416">                localWriteCacheBeingFlushed = writeCacheBeingFlushed;</span>
            } finally {
<span class="nc" id="L418">                writeCacheRotationLock.unlockRead(stamp);</span>
            }
        }

        // First try to read from the write cache of recent entries
<span class="nc" id="L423">        ByteBuf entry = localWriteCache.get(ledgerId, entryId);</span>
<span class="nc bnc" id="L424" title="All 2 branches missed.">        if (entry != null) {</span>
<span class="nc" id="L425">            recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L426">            recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L427">            return entry;</span>
        }

        // If there's a flush going on, the entry might be in the flush buffer
<span class="nc" id="L431">        entry = localWriteCacheBeingFlushed.get(ledgerId, entryId);</span>
<span class="nc bnc" id="L432" title="All 2 branches missed.">        if (entry != null) {</span>
<span class="nc" id="L433">            recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L434">            recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L435">            return entry;</span>
        }

        // Try reading from read-ahead cache
<span class="nc" id="L439">        entry = readCache.get(ledgerId, entryId);</span>
<span class="nc bnc" id="L440" title="All 2 branches missed.">        if (entry != null) {</span>
<span class="nc" id="L441">            recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L442">            recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L443">            return entry;</span>
        }

        // Read from main storage
        long entryLocation;
        try {
<span class="nc" id="L449">            entryLocation = entryLocationIndex.getLocation(ledgerId, entryId);</span>
<span class="nc bnc" id="L450" title="All 2 branches missed.">            if (entryLocation == 0) {</span>
<span class="nc" id="L451">                throw new NoEntryException(ledgerId, entryId);</span>
            }
<span class="nc" id="L453">            entry = entryLogger.readEntry(ledgerId, entryId, entryLocation);</span>
<span class="nc" id="L454">        } catch (NoEntryException e) {</span>
<span class="nc" id="L455">            recordFailedEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L456">            throw e;</span>
<span class="nc" id="L457">        }</span>

<span class="nc" id="L459">        readCache.put(ledgerId, entryId, entry);</span>

        // Try to read more entries
<span class="nc" id="L462">        long nextEntryLocation = entryLocation + 4 /* size header */ + entry.readableBytes();</span>
<span class="nc" id="L463">        fillReadAheadCache(ledgerId, entryId + 1, nextEntryLocation);</span>

<span class="nc" id="L465">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);</span>
<span class="nc" id="L466">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L467">        return entry;</span>
    }

    private void fillReadAheadCache(long orginalLedgerId, long firstEntryId, long firstEntryLocation) {
        try {
<span class="nc" id="L472">            long firstEntryLogId = (firstEntryLocation &gt;&gt; 32);</span>
<span class="nc" id="L473">            long currentEntryLogId = firstEntryLogId;</span>
<span class="nc" id="L474">            long currentEntryLocation = firstEntryLocation;</span>
<span class="nc" id="L475">            int count = 0;</span>
<span class="nc" id="L476">            long size = 0;</span>

<span class="nc bnc" id="L478" title="All 6 branches missed.">            while (count &lt; readAheadCacheBatchSize</span>
                    &amp;&amp; size &lt; maxReadAheadBytesSize
                    &amp;&amp; currentEntryLogId == firstEntryLogId) {
<span class="nc" id="L481">                ByteBuf entry = entryLogger.internalReadEntry(orginalLedgerId, firstEntryId, currentEntryLocation,</span>
                        false /* validateEntry */);

                try {
<span class="nc" id="L485">                    long currentEntryLedgerId = entry.getLong(0);</span>
<span class="nc" id="L486">                    long currentEntryId = entry.getLong(8);</span>

<span class="nc bnc" id="L488" title="All 2 branches missed.">                    if (currentEntryLedgerId != orginalLedgerId) {</span>
                        // Found an entry belonging to a different ledger, stopping read-ahead
                        break;
                    }

                    // Insert entry in read cache
<span class="nc" id="L494">                    readCache.put(orginalLedgerId, currentEntryId, entry);</span>

<span class="nc" id="L496">                    count++;</span>
<span class="nc" id="L497">                    firstEntryId++;</span>
<span class="nc" id="L498">                    size += entry.readableBytes();</span>

<span class="nc" id="L500">                    currentEntryLocation += 4 + entry.readableBytes();</span>
<span class="nc" id="L501">                    currentEntryLogId = currentEntryLocation &gt;&gt; 32;</span>
                } finally {
<span class="nc" id="L503">                    entry.release();</span>
                }
<span class="nc" id="L505">            }</span>

<span class="nc" id="L507">            dbLedgerStorageStats.getReadAheadBatchCountStats().registerSuccessfulValue(count);</span>
<span class="nc" id="L508">            dbLedgerStorageStats.getReadAheadBatchSizeStats().registerSuccessfulValue(size);</span>
<span class="nc" id="L509">        } catch (Exception e) {</span>
<span class="nc bnc" id="L510" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L511">                log.debug(&quot;Exception during read ahead for ledger: {}: e&quot;, orginalLedgerId, e);</span>
            }
<span class="nc" id="L513">        }</span>
<span class="nc" id="L514">    }</span>

    public ByteBuf getLastEntry(long ledgerId) throws IOException {
<span class="nc" id="L517">        long startTime = MathUtils.nowInNano();</span>

<span class="nc" id="L519">        long stamp = writeCacheRotationLock.readLock();</span>
        try {
            // First try to read from the write cache of recent entries
<span class="nc" id="L522">            ByteBuf entry = writeCache.getLastEntry(ledgerId);</span>
<span class="nc bnc" id="L523" title="All 2 branches missed.">            if (entry != null) {</span>
<span class="nc bnc" id="L524" title="All 2 branches missed.">                if (log.isDebugEnabled()) {</span>
<span class="nc" id="L525">                    long foundLedgerId = entry.readLong(); // ledgedId</span>
<span class="nc" id="L526">                    long entryId = entry.readLong();</span>
<span class="nc" id="L527">                    entry.resetReaderIndex();</span>
<span class="nc bnc" id="L528" title="All 2 branches missed.">                    if (log.isDebugEnabled()) {</span>
<span class="nc" id="L529">                        log.debug(&quot;Found last entry for ledger {} in write cache: {}@{}&quot;, ledgerId, foundLedgerId,</span>
<span class="nc" id="L530">                                entryId);</span>
                    }
                }

<span class="nc" id="L534">                recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L535">                recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L536">                return entry;</span>
            }

            // If there's a flush going on, the entry might be in the flush buffer
<span class="nc" id="L540">            entry = writeCacheBeingFlushed.getLastEntry(ledgerId);</span>
<span class="nc bnc" id="L541" title="All 2 branches missed.">            if (entry != null) {</span>
<span class="nc bnc" id="L542" title="All 2 branches missed.">                if (log.isDebugEnabled()) {</span>
<span class="nc" id="L543">                    entry.readLong(); // ledgedId</span>
<span class="nc" id="L544">                    long entryId = entry.readLong();</span>
<span class="nc" id="L545">                    entry.resetReaderIndex();</span>
<span class="nc bnc" id="L546" title="All 2 branches missed.">                    if (log.isDebugEnabled()) {</span>
<span class="nc" id="L547">                        log.debug(&quot;Found last entry for ledger {} in write cache being flushed: {}&quot;, ledgerId, entryId);</span>
                    }
                }

<span class="nc" id="L551">                recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span>
<span class="nc" id="L552">                recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L553">                return entry;</span>
            }
        } finally {
<span class="nc" id="L556">            writeCacheRotationLock.unlockRead(stamp);</span>
        }

        // Search the last entry in storage
<span class="nc" id="L560">        long lastEntryId = entryLocationIndex.getLastEntryInLedger(ledgerId);</span>
<span class="nc bnc" id="L561" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L562">            log.debug(&quot;Found last entry for ledger {} in db: {}&quot;, ledgerId, lastEntryId);</span>
        }

<span class="nc" id="L565">        long entryLocation = entryLocationIndex.getLocation(ledgerId, lastEntryId);</span>
<span class="nc" id="L566">        ByteBuf content = entryLogger.readEntry(ledgerId, lastEntryId, entryLocation);</span>

<span class="nc" id="L568">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);</span>
<span class="nc" id="L569">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span>
<span class="nc" id="L570">        return content;</span>
    }

    @VisibleForTesting
    boolean isFlushRequired() {
<span class="nc" id="L575">        long stamp = writeCacheRotationLock.readLock();</span>
        try {
<span class="nc bnc" id="L577" title="All 2 branches missed.">            return !writeCache.isEmpty();</span>
        } finally {
<span class="nc" id="L579">            writeCacheRotationLock.unlockRead(stamp);</span>
        }
    }

    @Override
    public void checkpoint(Checkpoint checkpoint) throws IOException {
<span class="nc" id="L585">        Checkpoint thisCheckpoint = checkpointSource.newCheckpoint();</span>
<span class="nc bnc" id="L586" title="All 2 branches missed.">        if (lastCheckpoint.compareTo(checkpoint) &gt; 0) {</span>
<span class="nc" id="L587">            return;</span>
        }

<span class="nc" id="L590">        long startTime = MathUtils.nowInNano();</span>

        // Only a single flush operation can happen at a time
<span class="nc" id="L593">        flushMutex.lock();</span>

        try {
            // Swap the write cache so that writes can continue to happen while the flush is
            // ongoing
<span class="nc" id="L598">            swapWriteCache();</span>

<span class="nc" id="L600">            long sizeToFlush = writeCacheBeingFlushed.size();</span>
<span class="nc bnc" id="L601" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L602">                log.debug(&quot;Flushing entries. count: {} -- size {} Mb&quot;, writeCacheBeingFlushed.count(),</span>
<span class="nc" id="L603">                        sizeToFlush / 1024.0 / 1024);</span>
            }

            // Write all the pending entries into the entry logger and collect the offset
            // position for each entry

<span class="nc" id="L609">            Batch batch = entryLocationIndex.newBatch();</span>
<span class="nc" id="L610">            writeCacheBeingFlushed.forEach((ledgerId, entryId, entry) -&gt; {</span>
                try {
<span class="nc" id="L612">                    long location = entryLogger.addEntry(ledgerId, entry, true);</span>
<span class="nc" id="L613">                    entryLocationIndex.addLocation(batch, ledgerId, entryId, location);</span>
<span class="nc" id="L614">                } catch (IOException e) {</span>
<span class="nc" id="L615">                    throw new RuntimeException(e);</span>
<span class="nc" id="L616">                }</span>
<span class="nc" id="L617">            });</span>

<span class="nc" id="L619">            entryLogger.flush();</span>

<span class="nc" id="L621">            long batchFlushStarTime = System.nanoTime();</span>
<span class="nc" id="L622">            batch.flush();</span>
<span class="nc" id="L623">            batch.close();</span>
<span class="nc bnc" id="L624" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L625">                log.debug(&quot;DB batch flushed time : {} s&quot;,</span>
<span class="nc" id="L626">                        MathUtils.elapsedNanos(batchFlushStarTime) / (double) TimeUnit.SECONDS.toNanos(1));</span>
            }

<span class="nc" id="L629">            ledgerIndex.flush();</span>

<span class="nc" id="L631">            cleanupExecutor.execute(() -&gt; {</span>
                // There can only be one single cleanup task running because the cleanupExecutor
                // is single-threaded
                try {
<span class="nc bnc" id="L635" title="All 2 branches missed.">                    if (log.isDebugEnabled()) {</span>
<span class="nc" id="L636">                        log.debug(&quot;Removing deleted ledgers from db indexes&quot;);</span>
                    }

<span class="nc" id="L639">                    entryLocationIndex.removeOffsetFromDeletedLedgers();</span>
<span class="nc" id="L640">                    ledgerIndex.removeDeletedLedgers();</span>
<span class="nc" id="L641">                } catch (Throwable t) {</span>
<span class="nc" id="L642">                    log.warn(&quot;Failed to cleanup db indexes&quot;, t);</span>
<span class="nc" id="L643">                }</span>
<span class="nc" id="L644">            });</span>

<span class="nc" id="L646">            lastCheckpoint = thisCheckpoint;</span>

            // Discard all the entry from the write cache, since they're now persisted
<span class="nc" id="L649">            writeCacheBeingFlushed.clear();</span>

<span class="nc" id="L651">            double flushTimeSeconds = MathUtils.elapsedNanos(startTime) / (double) TimeUnit.SECONDS.toNanos(1);</span>
<span class="nc" id="L652">            double flushThroughput = sizeToFlush / 1024.0 / 1024.0 / flushTimeSeconds;</span>

<span class="nc bnc" id="L654" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L655">                log.debug(&quot;Flushing done time {} s -- Written {} MB/s&quot;, flushTimeSeconds, flushThroughput);</span>
            }

<span class="nc" id="L658">            recordSuccessfulEvent(dbLedgerStorageStats.getFlushStats(), startTime);</span>
<span class="nc" id="L659">            dbLedgerStorageStats.getFlushSizeStats().registerSuccessfulValue(sizeToFlush);</span>
<span class="nc" id="L660">        } catch (IOException e) {</span>
            // Leave IOExecption as it is
<span class="nc" id="L662">            throw e;</span>
<span class="nc" id="L663">        } catch (RuntimeException e) {</span>
            // Wrap unchecked exceptions
<span class="nc" id="L665">            throw new IOException(e);</span>
        } finally {
            try {
<span class="nc" id="L668">                isFlushOngoing.set(false);</span>
            } finally {
<span class="nc" id="L670">                flushMutex.unlock();</span>
            }
        }
<span class="nc" id="L673">    }</span>

    /**
     * Swap the current write cache with the replacement cache.
     */
    private void swapWriteCache() {
<span class="nc" id="L679">        long stamp = writeCacheRotationLock.writeLock();</span>
        try {
            // First, swap the current write-cache map with an empty one so that writes will
            // go on unaffected. Only a single flush is happening at the same time
<span class="nc" id="L683">            WriteCache tmp = writeCacheBeingFlushed;</span>
<span class="nc" id="L684">            writeCacheBeingFlushed = writeCache;</span>
<span class="nc" id="L685">            writeCache = tmp;</span>

            // since the cache is switched, we can allow flush to be triggered
<span class="nc" id="L688">            hasFlushBeenTriggered.set(false);</span>
        } finally {
            try {
<span class="nc" id="L691">                isFlushOngoing.set(true);</span>
            } finally {
<span class="nc" id="L693">                writeCacheRotationLock.unlockWrite(stamp);</span>
            }
        }
<span class="nc" id="L696">    }</span>

    @Override
    public void flush() throws IOException {
<span class="nc" id="L700">        Checkpoint cp = checkpointSource.newCheckpoint();</span>
<span class="nc" id="L701">        checkpoint(cp);</span>
<span class="nc" id="L702">        checkpointSource.checkpointComplete(cp, true);</span>
<span class="nc" id="L703">    }</span>

    @Override
    public void deleteLedger(long ledgerId) throws IOException {
<span class="nc bnc" id="L707" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L708">            log.debug(&quot;Deleting ledger {}&quot;, ledgerId);</span>
        }

        // Delete entries from this ledger that are still in the write cache
<span class="nc" id="L712">        long stamp = writeCacheRotationLock.readLock();</span>
        try {
<span class="nc" id="L714">            writeCache.deleteLedger(ledgerId);</span>
        } finally {
<span class="nc" id="L716">            writeCacheRotationLock.unlockRead(stamp);</span>
        }

<span class="nc" id="L719">        entryLocationIndex.delete(ledgerId);</span>
<span class="nc" id="L720">        ledgerIndex.delete(ledgerId);</span>

<span class="nc bnc" id="L722" title="All 2 branches missed.">        for (int i = 0, size = ledgerDeletionListeners.size(); i &lt; size; i++) {</span>
<span class="nc" id="L723">            LedgerDeletionListener listener = ledgerDeletionListeners.get(i);</span>
<span class="nc" id="L724">            listener.ledgerDeleted(ledgerId);</span>
        }

<span class="nc" id="L727">        TransientLedgerInfo tli = transientLedgerInfoCache.remove(ledgerId);</span>
<span class="nc bnc" id="L728" title="All 2 branches missed.">        if (tli != null) {</span>
<span class="nc" id="L729">            tli.close();</span>
        }
<span class="nc" id="L731">    }</span>

    @Override
    public Iterable&lt;Long&gt; getActiveLedgersInRange(long firstLedgerId, long lastLedgerId) throws IOException {
<span class="nc" id="L735">        return ledgerIndex.getActiveLedgersInRange(firstLedgerId, lastLedgerId);</span>
    }

    @Override
    public void updateEntriesLocations(Iterable&lt;EntryLocation&gt; locations) throws IOException {
        // Trigger a flush to have all the entries being compacted in the db storage
<span class="nc" id="L741">        flush();</span>

<span class="nc" id="L743">        entryLocationIndex.updateLocations(locations);</span>
<span class="nc" id="L744">    }</span>

    @Override
    public EntryLogger getEntryLogger() {
<span class="nc" id="L748">        return entryLogger;</span>
    }

    @Override
    public long getLastAddConfirmed(long ledgerId) throws IOException {
<span class="nc" id="L753">        TransientLedgerInfo ledgerInfo = transientLedgerInfoCache.get(ledgerId);</span>
<span class="nc bnc" id="L754" title="All 2 branches missed.">        long lac = null != ledgerInfo ? ledgerInfo.getLastAddConfirmed() : TransientLedgerInfo.NOT_ASSIGNED_LAC;</span>
<span class="nc bnc" id="L755" title="All 2 branches missed.">        if (lac == TransientLedgerInfo.NOT_ASSIGNED_LAC) {</span>
<span class="nc" id="L756">            ByteBuf bb = getEntry(ledgerId, BookieProtocol.LAST_ADD_CONFIRMED);</span>
            try {
<span class="nc" id="L758">                bb.skipBytes(2 * Long.BYTES); // skip ledger id and entry id</span>
<span class="nc" id="L759">                lac = bb.readLong();</span>
<span class="nc" id="L760">                lac = getOrAddLedgerInfo(ledgerId).setLastAddConfirmed(lac);</span>
            } finally {
<span class="nc" id="L762">                bb.release();</span>
            }
        }
<span class="nc" id="L765">        return lac;</span>
    }

    @Override
    public boolean waitForLastAddConfirmedUpdate(long ledgerId, long previousLAC,
            Watcher&lt;LastAddConfirmedUpdateNotification&gt; watcher) throws IOException {
<span class="nc" id="L771">        return getOrAddLedgerInfo(ledgerId).waitForLastAddConfirmedUpdate(previousLAC, watcher);</span>
    }

    @Override
    public void cancelWaitForLastAddConfirmedUpdate(long ledgerId,
                                                    Watcher&lt;LastAddConfirmedUpdateNotification&gt; watcher)
            throws IOException {
<span class="nc" id="L778">        getOrAddLedgerInfo(ledgerId).cancelWaitForLastAddConfirmedUpdate(watcher);</span>
<span class="nc" id="L779">    }</span>

    @Override
    public void setExplicitLac(long ledgerId, ByteBuf lac) throws IOException {
<span class="nc" id="L783">        TransientLedgerInfo ledgerInfo = getOrAddLedgerInfo(ledgerId);</span>
<span class="nc" id="L784">        ledgerInfo.setExplicitLac(lac);</span>
<span class="nc" id="L785">        ledgerIndex.setExplicitLac(ledgerId, lac);</span>
<span class="nc" id="L786">        ledgerInfo.notifyWatchers(Long.MAX_VALUE);</span>
<span class="nc" id="L787">    }</span>

    @Override
    public ByteBuf getExplicitLac(long ledgerId) throws IOException {
<span class="nc bnc" id="L791" title="All 2 branches missed.">        if (log.isDebugEnabled()) {</span>
<span class="nc" id="L792">            log.debug(&quot;getExplicitLac ledger {}&quot;, ledgerId);</span>
        }
<span class="nc" id="L794">        TransientLedgerInfo ledgerInfo = getOrAddLedgerInfo(ledgerId);</span>
<span class="nc bnc" id="L795" title="All 2 branches missed.">        if (ledgerInfo.getExplicitLac() != null) {</span>
<span class="nc bnc" id="L796" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L797">                log.debug(&quot;getExplicitLac ledger {} returned from TransientLedgerInfo&quot;, ledgerId);</span>
            }
<span class="nc" id="L799">            return ledgerInfo.getExplicitLac();</span>
        }
        //LedgerData ledgerData = ledgerIndex.get(ledgerId);
        if (true) {
<span class="nc bnc" id="L803" title="All 2 branches missed.">            if (log.isDebugEnabled()) {</span>
<span class="nc" id="L804">                log.debug(&quot;getExplicitLac ledger {} missing from LedgerData&quot;, ledgerId);</span>
            }
<span class="nc" id="L806">            return null;</span>
        }
        if (true) {
            if (log.isDebugEnabled()) {
                log.debug(&quot;getExplicitLac ledger {} returned from LedgerData&quot;, ledgerId);
            }
            ByteString persistedLac = null;
            ledgerInfo.setExplicitLac(Unpooled.wrappedBuffer(persistedLac.toByteArray()));
        }
        return ledgerInfo.getExplicitLac();
    }

    private TransientLedgerInfo getOrAddLedgerInfo(long ledgerId) {
<span class="nc" id="L819">        return transientLedgerInfoCache.computeIfAbsent(ledgerId, l -&gt; {</span>
<span class="nc" id="L820">            return new TransientLedgerInfo(l, ledgerIndex);</span>
        });
    }

    private void updateCachedLacIfNeeded(long ledgerId, long lac) {
<span class="nc" id="L825">        TransientLedgerInfo tli = transientLedgerInfoCache.get(ledgerId);</span>
<span class="nc bnc" id="L826" title="All 2 branches missed.">        if (tli != null) {</span>
<span class="nc" id="L827">            tli.setLastAddConfirmed(lac);</span>
        }
<span class="nc" id="L829">    }</span>

    @Override
    public void flushEntriesLocationsIndex() throws IOException {
        // No-op. Location index is already flushed in updateEntriesLocations() call
<span class="nc" id="L834">    }</span>

    /**
     * Add an already existing ledger to the index.
     *
     * &lt;p&gt;This method is only used as a tool to help the migration from InterleaveLedgerStorage to DbLedgerStorage
     *
     * @param ledgerId
     *            the ledger id
     * @param pages
     *            Iterator over index pages from Indexed
     * @return the number of
     */
    public long addLedgerToIndex(long ledgerId, boolean isFenced, byte[] masterKey,
            LedgerCache.PageEntriesIterable pages) throws Exception {
        /*LedgerData ledgerData = LedgerData.newBuilder().setExists(true).setFenced(isFenced)
                .setMasterKey(ByteString.copyFrom(masterKey)).build();
        ledgerIndex.set(ledgerId, ledgerData);*/
<span class="nc" id="L852">        MutableLong numberOfEntries = new MutableLong();</span>

        // Iterate over all the entries pages
<span class="nc" id="L855">        Batch batch = entryLocationIndex.newBatch();</span>
<span class="nc bnc" id="L856" title="All 2 branches missed.">        for (LedgerCache.PageEntries page: pages) {</span>
<span class="nc" id="L857">            try (LedgerEntryPage lep = page.getLEP()) {</span>
<span class="nc" id="L858">                lep.getEntries((entryId, location) -&gt; {</span>
<span class="nc" id="L859">                    entryLocationIndex.addLocation(batch, ledgerId, entryId, location);</span>
<span class="nc" id="L860">                    numberOfEntries.increment();</span>
<span class="nc" id="L861">                    return true;</span>
                });
            }
<span class="nc" id="L864">        }</span>

<span class="nc" id="L866">        batch.flush();</span>
<span class="nc" id="L867">        batch.close();</span>

<span class="nc" id="L869">        return numberOfEntries.longValue();</span>
    }

    @Override
    public void registerLedgerDeletionListener(LedgerDeletionListener listener) {
<span class="nc" id="L874">        ledgerDeletionListeners.add(listener);</span>
<span class="nc" id="L875">    }</span>

    public EntryLocationIndex getEntryLocationIndex() {
<span class="nc" id="L878">        return entryLocationIndex;</span>
    }

    private void recordSuccessfulEvent(OpStatsLogger logger, long startTimeNanos) {
<span class="nc" id="L882">        logger.registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span>
<span class="nc" id="L883">    }</span>

    private void recordFailedEvent(OpStatsLogger logger, long startTimeNanos) {
<span class="nc" id="L886">        logger.registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span>
<span class="nc" id="L887">    }</span>

    long getWriteCacheSize() {
<span class="nc" id="L890">        return writeCache.size() + writeCacheBeingFlushed.size();</span>
    }

    long getWriteCacheCount() {
<span class="nc" id="L894">        return writeCache.count() + writeCacheBeingFlushed.count();</span>
    }

    long getReadCacheSize() {
<span class="nc" id="L898">        return readCache.size();</span>
    }

    long getReadCacheCount() {
<span class="nc" id="L902">        return readCache.count();</span>
    }

    @Override
    public List&lt;GarbageCollectionStatus&gt; getGarbageCollectionStatus() {
<span class="nc" id="L907">        return Collections.singletonList(gcThread.getGarbageCollectionStatus());</span>
    }

    /**
     * Interface which process ledger logger.
     */
    public interface LedgerLoggerProcessor {
        void process(long entryId, long entryLogId, long position);
    }

<span class="nc" id="L917">    private static final Logger log = LoggerFactory.getLogger(SingleDirectoryDbLedgerStorage.class);</span>

    @Override
    public OfLong getListOfEntriesOfLedger(long ledgerId) throws IOException {
<span class="nc" id="L921">        throw new UnsupportedOperationException(</span>
                &quot;getListOfEntriesOfLedger method is currently unsupported for SingleDirectoryDbLedgerStorage&quot;);
    }

    private LedgerDirsManager.LedgerDirsListener getLedgerDirsListener() {
<span class="nc" id="L926">        return new LedgerDirsListener() {</span>

            @Override
            public void diskAlmostFull(File disk) {
<span class="nc bnc" id="L930" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
<span class="nc" id="L931">                    gcThread.enableForceGC();</span>
                } else {
<span class="nc" id="L933">                    gcThread.suspendMajorGC();</span>
                }
<span class="nc" id="L935">            }</span>

            @Override
            public void diskFull(File disk) {
<span class="nc bnc" id="L939" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
<span class="nc" id="L940">                    gcThread.enableForceGC();</span>
                } else {
<span class="nc" id="L942">                    gcThread.suspendMajorGC();</span>
<span class="nc" id="L943">                    gcThread.suspendMinorGC();</span>
                }
<span class="nc" id="L945">            }</span>

            @Override
            public void allDisksFull(boolean highPriorityWritesAllowed) {
<span class="nc bnc" id="L949" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
<span class="nc" id="L950">                    gcThread.enableForceGC();</span>
                } else {
<span class="nc" id="L952">                    gcThread.suspendMajorGC();</span>
<span class="nc" id="L953">                    gcThread.suspendMinorGC();</span>
                }
<span class="nc" id="L955">            }</span>

            @Override
            public void diskWritable(File disk) {
                // we have enough space now
<span class="nc bnc" id="L960" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
                    // disable force gc.
<span class="nc" id="L962">                    gcThread.disableForceGC();</span>
                } else {
                    // resume compaction to normal.
<span class="nc" id="L965">                    gcThread.resumeMajorGC();</span>
<span class="nc" id="L966">                    gcThread.resumeMinorGC();</span>
                }
<span class="nc" id="L968">            }</span>

            @Override
            public void diskJustWritable(File disk) {
<span class="nc bnc" id="L972" title="All 2 branches missed.">                if (gcThread.isForceGCAllowWhenNoSpace()) {</span>
                    // if a disk is just writable, we still need force gc.
<span class="nc" id="L974">                    gcThread.enableForceGC();</span>
                } else {
                    // still under warn threshold, only resume minor compaction.
<span class="nc" id="L977">                    gcThread.resumeMinorGC();</span>
                }
<span class="nc" id="L979">            }</span>
        };
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.2.201808211720</span></div></body></html>